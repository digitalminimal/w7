{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "pipelines_challenge.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aPL7M2brSm8"
      },
      "source": [
        "## Pipelines Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF-qr192rSm9"
      },
      "source": [
        "In this challenge, we will be working with this [dataset](https://drive.google.com/file/d/1B07fvYosBNdIwlZxSmxDfeAf9KaygX89/view?usp=sharing), where we will be predicting sales. \n",
        "\n",
        "**The main goal is to create a `pipeline` that covers all the data preprocessing and modeling steps.**\n",
        "\n",
        "\n",
        "**TASK 1**: Build a pipeline that ends with a regression model, to predict `Item_Outlet_Sales` from the dataset. \n",
        "\n",
        "**The pipeline should have following steps:**\n",
        "\n",
        "1. Split the features into numerical and categorical (text)\n",
        "2. Replace null values\n",
        "    - the mean for numerical variables\n",
        "    - the most frequent value for categorical variables\n",
        "3. Create dummy variables from categorical features\n",
        "4. Use a PCA to reduce number of dummy variables to 3 principal components. PCA will be used directly after the OneHotEncoder that outputs data into a SparseMatrix, so we will need to use the **ToDenseTransformer** from the [article about custom pipelines](https://queirozf.com/entries/scikit-learn-pipelines-custom-pipelines-and-pandas-integration).\n",
        "5. Select the 3 best candidates from the original numerical features using KBest\n",
        "6. Fit a Ridge regression (default alpha is fine for now)\n",
        "\n",
        "**TASK 2**: Tune the parameters of multiple models as well as the preprocessing steps and find the best solution.\n",
        "- Try these models: \n",
        "        - Random Forest Regressor\n",
        "        - Gradient Boosting Regressor \n",
        "        - Ridge Regression. \n",
        "- For the task 2, we will need to use the same approach from this [earlier article](https://iaml.it/blog/optimizing-sklearn-pipelines), in the section `PIPELINE TUNING (ADVANCED VERSION)`, where we tried different kinds of scalers. (Use the article as reference.)\n",
        "\n",
        "_________________________________"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruk-HtxtrSm-",
        "outputId": "f3519505-9bd6-4a6b-9b1f-4b3c69f08bbb"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"regression_exercise.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Item_Identifier</th>\n",
              "      <th>Item_Weight</th>\n",
              "      <th>Item_Fat_Content</th>\n",
              "      <th>Item_Visibility</th>\n",
              "      <th>Item_Type</th>\n",
              "      <th>Item_MRP</th>\n",
              "      <th>Outlet_Identifier</th>\n",
              "      <th>Outlet_Establishment_Year</th>\n",
              "      <th>Outlet_Size</th>\n",
              "      <th>Outlet_Location_Type</th>\n",
              "      <th>Outlet_Type</th>\n",
              "      <th>Item_Outlet_Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FDA15</td>\n",
              "      <td>9.30</td>\n",
              "      <td>Low Fat</td>\n",
              "      <td>0.016047</td>\n",
              "      <td>Dairy</td>\n",
              "      <td>249.8092</td>\n",
              "      <td>OUT049</td>\n",
              "      <td>1999</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Tier 1</td>\n",
              "      <td>Supermarket Type1</td>\n",
              "      <td>3735.1380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DRC01</td>\n",
              "      <td>5.92</td>\n",
              "      <td>Regular</td>\n",
              "      <td>0.019278</td>\n",
              "      <td>Soft Drinks</td>\n",
              "      <td>48.2692</td>\n",
              "      <td>OUT018</td>\n",
              "      <td>2009</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Tier 3</td>\n",
              "      <td>Supermarket Type2</td>\n",
              "      <td>443.4228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FDN15</td>\n",
              "      <td>17.50</td>\n",
              "      <td>Low Fat</td>\n",
              "      <td>0.016760</td>\n",
              "      <td>Meat</td>\n",
              "      <td>141.6180</td>\n",
              "      <td>OUT049</td>\n",
              "      <td>1999</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Tier 1</td>\n",
              "      <td>Supermarket Type1</td>\n",
              "      <td>2097.2700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FDX07</td>\n",
              "      <td>19.20</td>\n",
              "      <td>Regular</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Fruits and Vegetables</td>\n",
              "      <td>182.0950</td>\n",
              "      <td>OUT010</td>\n",
              "      <td>1998</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tier 3</td>\n",
              "      <td>Grocery Store</td>\n",
              "      <td>732.3800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NCD19</td>\n",
              "      <td>8.93</td>\n",
              "      <td>Low Fat</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Household</td>\n",
              "      <td>53.8614</td>\n",
              "      <td>OUT013</td>\n",
              "      <td>1987</td>\n",
              "      <td>High</td>\n",
              "      <td>Tier 3</td>\n",
              "      <td>Supermarket Type1</td>\n",
              "      <td>994.7052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
              "0           FDA15         9.30          Low Fat         0.016047   \n",
              "1           DRC01         5.92          Regular         0.019278   \n",
              "2           FDN15        17.50          Low Fat         0.016760   \n",
              "3           FDX07        19.20          Regular         0.000000   \n",
              "4           NCD19         8.93          Low Fat         0.000000   \n",
              "\n",
              "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
              "0                  Dairy  249.8092            OUT049   \n",
              "1            Soft Drinks   48.2692            OUT018   \n",
              "2                   Meat  141.6180            OUT049   \n",
              "3  Fruits and Vegetables  182.0950            OUT010   \n",
              "4              Household   53.8614            OUT013   \n",
              "\n",
              "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
              "0                       1999      Medium               Tier 1   \n",
              "1                       2009      Medium               Tier 3   \n",
              "2                       1999      Medium               Tier 1   \n",
              "3                       1998         NaN               Tier 3   \n",
              "4                       1987        High               Tier 3   \n",
              "\n",
              "         Outlet_Type  Item_Outlet_Sales  \n",
              "0  Supermarket Type1          3735.1380  \n",
              "1  Supermarket Type2           443.4228  \n",
              "2  Supermarket Type1          2097.2700  \n",
              "3      Grocery Store           732.3800  \n",
              "4  Supermarket Type1           994.7052  "
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "UXfFNslzrSm_",
        "outputId": "5dba5aa2-0bbf-4ef3-9c76-f89b08bc9b35"
      },
      "source": [
        "# creating target variable\n",
        "y = df[\"Item_Outlet_Sales\"]\n",
        "df = df.drop([\"Item_Outlet_Sales\",\"Item_Identifier\"],axis = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4bbd79b383ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# creating target variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Item_Outlet_Sales\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Item_Outlet_Sales\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Item_Identifier\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f2hYs-HrSm_"
      },
      "source": [
        "Split the dataset into a train and test set.\n",
        "\n",
        "**Note:** We should always do this at the beginning before the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iToOXhcsrSm_"
      },
      "source": [
        "df_train = df.sample(frac=0.8).sort_index()\n",
        "y_train = y[y.index.isin(df_train.index.tolist())]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o80smJKCrSnA"
      },
      "source": [
        "df_test = df[~df.index.isin(df_train.index.tolist())].sort_index()\n",
        "y_test = y[y.index.isin(df_test.index.tolist())]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-ukfRDMrSnA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGqckoWbrSnA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1OfsEJ1rSnA"
      },
      "source": [
        "---------------------\n",
        "## Task I\n",
        "\n",
        "### Split Features into numerical and categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us0Ydjv_rSnA"
      },
      "source": [
        "cat_feats = df.dtypes[df.dtypes == 'object'].index.tolist()\n",
        "num_feats = df.dtypes[~df.dtypes.index.isin(cat_feats)].index.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5bLHqWKrSnB"
      },
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Using own function in Pipeline\n",
        "def numFeat(data):\n",
        "    return data[num_feats]\n",
        "\n",
        "def catFeat(data):\n",
        "    return data[cat_feats]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03qPet81rSnB"
      },
      "source": [
        "# we will start two separate pipelines for each type of features\n",
        "keep_num = FunctionTransformer(numFeat)\n",
        "keep_cat = FunctionTransformer(catFeat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvLxai95rSnB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLA8M5nprSnB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_assfj_urSnB"
      },
      "source": [
        "### replacing null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w55lR5r2rSnB"
      },
      "source": [
        "# Use SimpleImputer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2kDixRsrSnB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-18CL08mrSnC"
      },
      "source": [
        "### Creating dummy variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN9iWl8urSnC"
      },
      "source": [
        "# use OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWWoFh6LrSnC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj8MsHeZrSnC"
      },
      "source": [
        "### Use PCA to reduce the number of dummy variables to 3 principal components."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz7pl7NVrSnC"
      },
      "source": [
        "# don't forget ToDenseTransformer after one hot encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWJKZqj0rSnC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YPhaFcMrSnC"
      },
      "source": [
        "### Select the 3 best numeric features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDH9m4zMrSnC"
      },
      "source": [
        "# use SelectKBest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy0kpaJArSnD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTLzcEx5rSnD"
      },
      "source": [
        "### Fitting models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66KeyQgIrSnD"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Use base_model in Task I\n",
        "base_model = Ridge()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQtOW7RSrSnD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucarR2aFrSnD"
      },
      "source": [
        "### Building a Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToSIoeeLrSnD"
      },
      "source": [
        "from sklearn.pipeline import Pipeline, FeatureUnion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZvUz163rSnD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKGlAGM5rSnE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trH4fxNyrSnE"
      },
      "source": [
        "# model.score(df_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkf_JSCKrSnE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z93BVQfWrSnE"
      },
      "source": [
        "----------------------------\n",
        "## Task II"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyKliOkerSnE"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPH0o-SDrSnE"
      },
      "source": [
        "params = [\n",
        "# \n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XWDKiMyrSnE",
        "outputId": "3f123546-39da-47a6-bcf2-5bdb085b4d66"
      },
      "source": [
        "# print('Final score is: ', tuned_model.score(df_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final score is:  0.6241741712069144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R81s_iA1rSnF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}